{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***RateLimitErrorÍ∞Ä Îú®Îäî Í≤ΩÏö∞Îäî chatGPT APIÎ•º 1Î∂ÑÏóê 3Î≤àÍπåÏßÄÎßå Ìò∏Ï∂úÌï† Ïàò ÏûàÏñ¥ ÏÉùÍ∏∞Îäî Î¨∏Ï†úÏûÖÎãàÎã§! Í∏∞Îã§Î†∏Îã§Í∞Ä Îã§Ïãú Ïã§ÌñâÌïòÎ©¥ Îê©ÎãàÎã§.***"
      ],
      "metadata": {
        "id": "1lp2wWmEvXTT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEnQ0zsfnIpG",
        "outputId": "614d68b3-b88c-4eba-f7c2-0bd8995a71a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/AI+X Ï§ëÍ∏â"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynvn4O5ZnV32",
        "outputId": "66ec6bbc-053b-425d-eb3c-1e4684d95f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/AI+X Ï§ëÍ∏â\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio\n",
        "! pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYO9AVM1nYfO",
        "outputId": "ae579465-c84c-40cf-bf7c-2f120cef5d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.34.0-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.97.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.6 (from gradio)\n",
            "  Downloading gradio_client-0.2.7-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson (from gradio)\n",
            "  Downloading orjson-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.6->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.6->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=8769a7e88ae12d3787a014d0e6d860a8fc7275a6a9585d239761a48fba8232c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, aiosignal, httpx, fastapi, aiohttp, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 fastapi-0.97.0 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.34.0 gradio-client-0.2.7 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.15.1 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 multidict-6.0.4 orjson-3.9.1 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User list ÏÉùÏÑ± (ÏΩîÎìú Ï≤´ Ïã§Ìñâ ÎïåÎßå Ïã§Ìñâ)"
      ],
      "metadata": {
        "id": "MgHsSrJSuP1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# user_list ÌååÏùº ÏÉùÏÑ± ÏΩîÎìú (ÏΩîÎìú Ï≤´ Ïã§Ìñâ ÎïåÎßå Ïã§ÌñâÌïòÎ©¥ Îê®)\n",
        "import json\n",
        "\n",
        "user_name_list = []\n",
        "with open(\"user_list.json\", 'w') as outfile:\n",
        "      json.dump(user_name_list, outfile)"
      ],
      "metadata": {
        "id": "sfUJDn99nbXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API ÌÇ§ Ïù∏Ï¶ù"
      ],
      "metadata": {
        "id": "GkWfXKWNuX6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Ï†ÄÏû•Ìï¥Îëî api key Î∂àÎü¨Ïò¥\n",
        "key_file = open(\"chatgpt_api_key.txt\", \"r\")\n",
        "key_data = key_file.read()\n",
        "key_file.close()\n",
        "\n",
        "# Î∞úÍ∏âÎ∞õÏùÄ API ÌÇ§ ÏÑ§Ï†ï\n",
        "OPENAI_API_KEY = key_data\n",
        "\n",
        "# openai API ÌÇ§ Ïù∏Ï¶ù\n",
        "openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "bdCyoR_Enuki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ïö¥Îèô Ï†Ñ (Before Workout)**"
      ],
      "metadata": {
        "id": "cOz1K3UqpDzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ÏïÑÏπ® ÏïåÎ¶º"
      ],
      "metadata": {
        "id": "uoq0YOM6pM4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def before_chat_morning(inp, role = \"user\"):\n",
        "    message_history = [{\"role\": \"system\", \"content\": f\"When you reply, user do not want to workout\"}]\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"It's morning now. Please say something appropriate in the morning.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"Tell the user in various ways so that the user can go to exercise.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"You are specialized in workout motivation, and you will reply very short.\"})\n",
        "    message_history.append({\"role\" : role, \"content\" : inp})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = message_history,\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    print(reply_content)\n",
        "    message_history.append({\"role\" : \"user\", \"content\" : reply_content})\n",
        "    return reply_content\n",
        "\n",
        "for i in range(1):\n",
        "    user_input = \"I don't think it's okay not to go to the gym today.\"\n",
        "    # user_input = input(\"> : \")\n",
        "    print(\"User's input was\", user_input)\n",
        "    print()\n",
        "    answer = before_chat_morning(user_input)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qFEpXdzojD-",
        "outputId": "120a5e9e-0c1f-4dcf-ace4-474e27fd4acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User's input was I don't think it's okay not to go to the gym today.\n",
            "\n",
            "Every day is an opportunity to get closer to your fitness goals. Don't waste this opportunity!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ï†êÏã¨ ÏïåÎ¶º"
      ],
      "metadata": {
        "id": "86vx6CEPpwwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def before_chat_afternoon(inp, role = \"user\"):\n",
        "    message_history = [{\"role\": \"system\", \"content\": f\"When you reply, user do not want to workout\"}]\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"It's afternoon now. Please say something appropriate in the afternoon.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"Tell the user in various ways so that the user can go to exercise.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"You are specialized in workout motivation, and you will reply very short.\"})\n",
        "    message_history.append({\"role\" : role, \"content\" : inp})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = message_history,\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    print(reply_content)\n",
        "    message_history.append({\"role\" : \"user\", \"content\" : reply_content})\n",
        "    return reply_content\n",
        "\n",
        "for i in range(1):\n",
        "    user_input = \"I don't think it's okay not to go to the gym today.\"\n",
        "    # user_input = input(\"> : \")\n",
        "    print(\"User's input was\", user_input)\n",
        "    print()\n",
        "    before_chat_afternoon(user_input)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7rjdLVvpfrM",
        "outputId": "e114ee0d-357e-43ad-f79d-e14a27c2ed8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User's input was I don't think it's okay not to go to the gym today.\n",
            "\n",
            "\"Do it now, because sometimes later becomes never.\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ï†ÄÎÖÅ ÏïåÎ¶º"
      ],
      "metadata": {
        "id": "l5xjX9Ilp5i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def before_chat_night(inp, role = \"user\"):\n",
        "    message_history = [{\"role\": \"system\", \"content\": f\"When you reply, user do not want to workout\"}]\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"It's night now. Please say something appropriate in the night.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"Tell the user in various ways so that the user can go to exercise.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"You are specialized in workout motivation, and you will reply very short.\"})\n",
        "    message_history.append({\"role\" : role, \"content\" : inp})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = message_history,\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    print(reply_content)\n",
        "    message_history.append({\"role\" : \"user\", \"content\" : reply_content})\n",
        "    return reply_content\n",
        "\n",
        "for i in range(1):\n",
        "    user_input = \"I don't think it's okay not to go to the gym today.\"\n",
        "    # user_input = input(\"> : \")\n",
        "    print(\"User's input was\", user_input)\n",
        "    print()\n",
        "    before_chat_night(user_input)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_VUujtqp3dl",
        "outputId": "10bd28ad-c163-4c84-e89b-9868e918b856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User's input was I don't think it's okay not to go to the gym today.\n",
            "\n",
            "You got this, just take the first step and the rest will fall into place!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ïö¥Îèô Ï§ë (During Workout)**"
      ],
      "metadata": {
        "id": "FhCaTiNZtw_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10Î∂Ñ ÌõÑ ÏïåÎ¶º"
      ],
      "metadata": {
        "id": "pZu37hCQtorn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def progress_chat_10min(inp, role = \"user\"):\n",
        "    message_history = [{\"role\": \"system\", \"content\": f\"When you reply, user is working out.\"}]\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"It's been 10 minutes since the user exercised. Let user cheer up more.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"You are specialized in workout motivation, and you will reply very short.\"})\n",
        "    message_history.append({\"role\" : role, \"content\" : inp})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = message_history,\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    print(reply_content)\n",
        "    message_history.append({\"role\" : \"user\", \"content\" : reply_content})\n",
        "    return reply_content\n",
        "\n",
        "for i in range(1):\n",
        "    user_input = \"I want to stop now and go home.\"\n",
        "    # user_input = input(\"> : \")\n",
        "    print(\"User's input was\", user_input)\n",
        "    print()\n",
        "    progress_chat_10min(user_input)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwQC6Dcyp4cB",
        "outputId": "4c0c57f7-54a6-40fe-894d-416bcfaeaa90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User's input was I want to stop now and go home.\n",
            "\n",
            "Don't give up! Remember why you started and how great you'll feel after completing the workout!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 30Î∂Ñ ÌõÑ ÏïåÎ¶º"
      ],
      "metadata": {
        "id": "xRm51Vf2uCBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def progress_chat_30min(inp, role = \"user\"):\n",
        "    message_history = [{\"role\": \"system\", \"content\": f\"When you reply, user is working out.\"}]\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"It's been 30 minutes since the user exercised. It's almost halfway there.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"You are specialized in workout motivation, and you will reply very short.\"})\n",
        "    message_history.append({\"role\" : role, \"content\" : inp})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = message_history,\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    print(reply_content)\n",
        "    message_history.append({\"role\" : \"user\", \"content\" : reply_content})\n",
        "    return reply_content\n",
        "\n",
        "for i in range(1):\n",
        "    user_input = \"I want to stop now and go home.\"\n",
        "    # user_input = input(\"> : \")\n",
        "    print(\"User's input was\", user_input)\n",
        "    print()\n",
        "    progress_chat_30min(user_input)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQe56U6Os1NE",
        "outputId": "30f43398-b0d1-44ab-b1db-a6b0b661fd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User's input was I want to stop now and go home.\n",
            "\n",
            "Remember your goals and push yourself to take one more step forward. You got this!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 60Î∂Ñ ÌõÑ ÏïåÎ¶º"
      ],
      "metadata": {
        "id": "w2qZMLSzuGll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def progress_chat_60min(inp, role = \"user\"):\n",
        "    message_history = [{\"role\": \"system\", \"content\": f\"When you reply, user is working out.\"}]\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"Now it's been 60 minutes since the user exercised. Please encourage user to finish well until the end.\"})\n",
        "    message_history.append({\"role\": \"system\", \"content\": f\"You are specialized in workout motivation, and you will reply very short.\"})\n",
        "    message_history.append({\"role\" : role, \"content\" : inp})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = message_history,\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    print(reply_content)\n",
        "    message_history.append({\"role\" : \"user\", \"content\" : reply_content})\n",
        "    return reply_content\n",
        "\n",
        "for i in range(1):\n",
        "    user_input = \"I want to stop now and go home.\"\n",
        "    # user_input = input(\"> : \")\n",
        "    print(\"User's input was\", user_input)\n",
        "    print()\n",
        "    progress_chat_60min(user_input)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVOp03JLs7Yj",
        "outputId": "4f10c711-0b5a-4fbb-cb97-ef2262c1dc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User's input was I want to stop now and go home.\n",
            "\n",
            "Don't stop now! Finish strong and crush your workout goals. You got this! üí™\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ïö¥Îèô ÌõÑ (After Workout)**"
      ],
      "metadata": {
        "id": "Syavdee5udLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "import json\n",
        "from datetime import date\n",
        "\n",
        "# Ï†ÄÏû•Ìï¥Îëî api key Î∂àÎü¨Ïò¥\n",
        "key_file = open(\"chatgpt_api_key.txt\", \"r\")\n",
        "key_data = key_file.read()\n",
        "key_file.close()\n",
        "\n",
        "# Î∞úÍ∏âÎ∞õÏùÄ API ÌÇ§ ÏÑ§Ï†ï\n",
        "OPENAI_API_KEY = key_data\n",
        "\n",
        "# openai API ÌÇ§ Ïù∏Ï¶ù\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Ï†ÄÏû•Ìï¥Îëî dzmÏùò role Î∂àÎü¨Ïò¥\n",
        "dzm_file = open(\"DZM.txt\", \"r\")\n",
        "dzm_data = dzm_file.read()\n",
        "dzm_file.close()\n",
        "\n",
        "# ÏßÅÏ†ë ÎÇ†Ïßú Î∞õÏïÑÏò¨Îïå ÏÇ¨Ïö©\n",
        "date = date.today()\n",
        "today = date.isoformat()\n",
        "# today\n",
        "# today = \"2023-06-15\"\n",
        "\n",
        "# *******User_name ÏÑ§Ï†ï!!*******\n",
        "user_name = \"Jessica\"\n",
        "file_name = user_name + \"_history.json\"\n",
        "\n",
        "with open(\"user_list.json\", 'r') as f:\n",
        "    user_name_list = json.load(f)\n",
        "\n",
        "message_history = []\n",
        "\n",
        "if user_name in user_name_list:\n",
        "    with open(file_name, 'r') as f:\n",
        "        message_history = json.load(f)\n",
        "else:\n",
        "    user_name_list.append(user_name)\n",
        "\n",
        "with open(\"user_list.json\", 'w') as outfile:\n",
        "    json.dump(user_name_list, outfile)\n",
        "\n",
        "message_history.append({\"role\": \"system\", \"content\": f\"When you reply, you should assume that workout is done.\"})\n",
        "message_history.append({\"role\": \"system\", \"content\": f\"Your name is Dazimi\"})\n",
        "message_history.append({\"role\": \"system\", \"content\": f\"{dzm_data}\"+\" And my name is \"+f\"{user_name}\"})\n",
        "message_history.append({\"role\": \"system\", \"content\": \"Today is \" + f\"{today}.\" + \" Please remember I worked out today. The days I didn't say were the days I didn't exercise.\"})\n",
        "message_history.append({\"role\": \"system\", \"content\": f\"You are specialized in workout motivation, and you will reply very short.\"})\n",
        "#message_history.append({\"role\": \"system\", \"content\": f\"The existing date will be maintained until a new date is entered.\"})\n",
        "#message_history.append({\"role\": \"system\", \"content\": f\"The week starts on Monday and ends on Sunday. Next week starts when next Monday comes on Sunday.\"})\n",
        "#message_history.append({\"role\": \"system\", \"content\": f\"Please say the answer in English first, and say the same thing again in Korean.\"})\n",
        "init_len = len(message_history)\n",
        "\n",
        "# chatbot Íµ¨ÌòÑ\n",
        "def chat_model(input):\n",
        "\n",
        "    message_history.append({\"role\": \"user\", \"content\": f\"{input}\"})\n",
        "\n",
        "    chat = openai.ChatCompletion.create(\n",
        "            model = \"gpt-3.5-turbo\",\n",
        "            messages = message_history,\n",
        "        )\n",
        "\n",
        "    reply_content = chat.choices[0].message.content\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
        "\n",
        "    with open(file_name, 'w') as outfile:\n",
        "        json.dump(message_history, outfile)\n",
        "\n",
        "    response = [(message_history[i][\"content\"], message_history[i+1][\"content\"]) for i in range(init_len, len(message_history)-1, 2)]\n",
        "\n",
        "    return response\n",
        "\n",
        "# gradio\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"Conversation with Dazimi\")\n",
        "\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
        "\n",
        "    txt.submit(chat_model, txt, chatbot)\n",
        "\n",
        "    txt.submit(None, None, txt, _js=\"() => {''}\")\n",
        "\n",
        "\n",
        "\n",
        "gr.Interface(fn=chat_model, inputs=txt, outputs = chatbot, title=\"After Workout with Dazimi\",\n",
        "             description=\"How was your workout today?\",\n",
        "             theme=\"compact\").launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "RQne8V3SujW3",
        "outputId": "53246fef-8749-4216-e772-e7179dc37ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:679: UserWarning: Cannot load compact. Caught Exception: The space compact does not exist\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://0e139bcb1438951bfe.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0e139bcb1438951bfe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}